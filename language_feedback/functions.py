import openai 

def generate_prompt(instructions, title, text):
    """This function creates a prompt that can be used
    by GPT-3 to generate a summary of a given text.

    Args:
        instructions (str): Instructions can improve the summarization quality
        title (str): Title of the text
        text (str): Some text to be summarized 
    """
     
    prompt = f"""{instructions}
TITLE: {title}\n 
Text: {text}\n
TL;DR:
"""
    return prompt
    
    
def generate_summary(prompt, 
                     model="text-davinci-001",
                     max_tokens=48,
                     top_p=0.9,
                     n=5):
    """This function receives a prompt and uses the OpenAI API to generate a summary.

    Args:
        prompt (str): Prompt as generated by generate_prompt function
        model (str, optional): OpenAI model used to generate the summary. Defaults to "text-davinci-001".
        max_tokens (int, optional): Maximum output length of summary in tokens. Defaults to 48.
        top_p (float, optional): Considers outputs only until cummulative probability of top_p is reached. Defaults to 0.9.
        n (int, optional): Number of generated summaries. Defaults to 5.

    Returns:
        _type_: _description_
    """    
    model_output = openai.Completion.create(
                        model=model,
                        prompt=prompt,
                        max_tokens=max_tokens,
                        temperature=top_p,
                        n=n
                        )
    
    return model_output


def generate_refinements(model_output):
    """
    For all summarization experiments (§3.2), we sample up to 48 tokens (as in Stiennon et al., 2020) 
    with nucleus sampling (Holtzman et al., 2019) with p = 0.9. 
    We strip nonalphanumeric characters (e.g., newlines) from the beginning of sampled summaries. 
    Due to the maximum token length, sampled summaries sometimes end with an incomplete sentence. 
    Thus, we remove ending sentences that do not end in “.”, “!”, or “?”.
    """
    
    model_output = model_output.lstrip()
    
    if model_output[-1] not in ['.', '!', '?']:
        return 
    
    return model_output